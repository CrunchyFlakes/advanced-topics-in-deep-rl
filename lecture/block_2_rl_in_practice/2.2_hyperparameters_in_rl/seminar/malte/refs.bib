@article{evolving_population,
title = {Evolving population method for real-time reinforcement learning},
journal = {Expert Systems with Applications},
volume = {229},
pages = {120493},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120493},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423009958},
author = {Man-Je Kim and Jun Suk Kim and Chang Wook Ahn},
keywords = {Reinforcement learning, Deep Q network, Monte Carlo tree search, Real-time reinforcement learning, Genetic algorithm},
abstract = {Reinforcement learning has recently been recognized as a promising means of machine learning, but its applicability remains limited in real-time environment due to its short response time, high computational complexity, and instability in learning. Although researchers devised several measures in attempts to press beyond the horizon, the problems consisting of large branching factors with real-time properties still stays unconquered, demanding a new method for reinforcement learning as a whole. In this paper, we propose Evolving Population. This method improves the performance of reinforcement learning by optimizing hyperparameters and available actions. This method uses an iterative structure based on an evolutionary strategy to optimize these elements. We validate the performance of our method in an environment with real-time properties and large branching factors.}
}

@inproceedings{action_sequences,
author = {Kim, Man-Je and Kim, Jun Suk and Lee, Donghyeon and Kim, Sungjin James and Kim, Min-Jung and Ahn, Chang Wook},
title = {Integrating agent actions with genetic action sequence method},
year = {2019},
isbn = {9781450367486},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319619.3326772},
doi = {10.1145/3319619.3326772},
abstract = {Reinforcement learning in general is suitable for putting actions in a specific order within a short sequence, but in the long run its greedy nature leads to eventual incompetence. This paper presents a brief description and implementative analysis of Action Sequence which was designed to deal with such a "penny-wise and pound-foolish" problem. Based on a combination of genetic operations and Monte-Carlo tree search, our proposed method is expected to show improved computational efficiency especially on problems with high complexity in which situational difficulties are often troublesome to resolve with naive behaviors. We tested the method on a video game environment to validate its overall performance.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {59â€“60},
numpages = {2},
keywords = {video game, evolutionary computing and genetic algorithms, artificial intelligence},
location = {Prague, Czech Republic},
series = {GECCO '19}
}
